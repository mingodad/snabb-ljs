module(..., package.seeall);

var ffi = require("ffi");
var C = ffi.C;
var S = require("syscall");
var lib = require("core.lib");
var binary_search = require("lib.binary_search");
var multi_copy = require("lib.multi_copy");
var siphash = require("lib.hash.siphash");
var min, max, floor, ceil = math.min, math.max, math.floor, math.ceil;

CTable = {};
LookupStreamer = {};

var HASH_MAX = 0xFFFFFFFF;
var uint8_ptr_t = ffi.typeof('uint8_t*');
var uint16_ptr_t = ffi.typeof('uint16_t*');
var uint32_ptr_t = ffi.typeof('uint32_t*');
var uint64_ptr_t = ffi.typeof('uint64_t*');

var function compute_hash_fn(key_ctype, seed) {
   if( tonumber(ffi.new(key_ctype)) ) {
      return siphash.make_u64_hash({c=1, d=2, key=seed});
   } else {
      return siphash.make_hash({c=1, d=2, size=ffi.sizeof(key_ctype),
                                key=seed});
   }
}

var function compute_multi_hash_fn(key_ctype, width, stride, seed) {
   if( tonumber(ffi.new(key_ctype)) ) {
      // We could fix this, but really it would be nicest to prohibit
      // scalar keys.
      error('streaming lookup not available for scalar keys');
   }
   return siphash.make_multi_hash({c=1, d=2, size=ffi.sizeof(key_ctype),
                                   width=width, stride=stride, key=seed});
}

var entry_types = {};
var function make_entry_type(key_type, value_type) {
   var cache = entry_types[key_type];
   if( cache ) {
      cache = cache[value_type];
      if( cache ) { return cache; }
   } else {
      entry_types[key_type] = {};
   }
   var raw_size = ffi.sizeof(key_type) + ffi.sizeof(value_type) + 4;
   var padding = 2**ceil(math.log(raw_size)/math.log(2)) - raw_size;
   var ret = ffi.typeof([=[struct {
         uint32_t hash;
         $ key;
         $ value;
         uint8_t padding[$];
      } __attribute__((packed))]=],
      key_type,
      value_type,
      padding);
   entry_types[key_type][value_type] = ret;
   return ret;
}

var function make_entries_type(entry_type) {
   return (ffi.typeof('$[?]', entry_type));
}

// hash := [0,HASH_MAX); scale := size/HASH_MAX
var function hash_to_index(hash, scale) {
   return (floor(hash*scale));
}

var function make_equal_fn(key_type) {
   var size = ffi.sizeof(key_type);
   var cast = ffi.cast;
   if( tonumber(ffi.new(key_type)) ) {
      return function (a, b) {
         return a == b;
      };
   } else if( size == 2 ) {
      return function (a, b) {
         return cast(uint16_ptr_t, a)[0] == cast(uint16_ptr_t, b)[0];
      };
   } else if( size == 4 ) {
      return function (a, b) {
         return cast(uint32_ptr_t, a)[0] == cast(uint32_ptr_t, b)[0];
      };
   } else if( size == 6 ) {
      return function (a, b) {
         return (cast(uint32_ptr_t, a)[0] == cast(uint32_ptr_t, b)[0] &&
                 cast(uint16_ptr_t, a)[2] == cast(uint16_ptr_t, b)[2]);
      };
   } else if( size == 8 ) {
      return function (a, b) {
         return cast(uint64_ptr_t, a)[0] == cast(uint64_ptr_t, b)[0];
      };
   } else {
      return function (a, b) {
         return C.memcmp(a, b, size) == 0;
      };
   }
}

var function parse_params(params, required, optional) {
   var ret = {};
   for( k, _ in pairs(required) ) {
      if( params[k] == null ) { error('missing required option ' .. k); }
   }
   for( k, v in pairs(params) ) {
      if( ! required[k] && optional[k] == null ) {
         error('unrecognized option ' .. k);
      }
      ret[k] = v;
   }
   for( k, v in pairs(optional) ) {
      if( ret[k] == null ) { ret[k] = v; }
   }
   return ret;
}

// FIXME: For now the value_type option is required, but in the future
// we should allow for a nil value type to create a set instead of a
// map.
var required_params = lib.set('key_type', 'value_type');
var optional_params = {
   hash_seed = false,
   initial_size = 8,
   max_occupancy_rate = 0.9,
   min_occupancy_rate = 0.0,
   resize_callback = false
};

function new(params) {
   var ctab = {};   
   params = parse_params(params, required_params, optional_params);
   ctab.entry_type = make_entry_type(params.key_type, params.value_type);
   ctab.type = make_entries_type(ctab.entry_type);
   function ctab.make_hash_fn() {
      return compute_hash_fn(params.key_type, ctab.hash_seed);
   }
   function ctab.make_multi_hash_fn(width) {
      var stride, seed = ffi.sizeof(ctab.entry_type), ctab.hash_seed;
      return compute_multi_hash_fn(params.key_type, width, stride, seed);
   }
   ctab.equal_fn = make_equal_fn(params.key_type);
   ctab.size = 0;
   ctab.max_displacement = 0;
   ctab.occupancy = 0;
   ctab.max_occupancy_rate = params.max_occupancy_rate;
   ctab.min_occupancy_rate = params.min_occupancy_rate;
   ctab.resize_callback = params.resize_callback;
   ctab = setmetatable(ctab, { __index = CTable });
   ctab->reseed_hash_function(params.hash_seed);
   ctab->resize(params.initial_size);
   return ctab;
}

// FIXME: There should be a library to help allocate anonymous
// hugepages, not this code.
var try_huge_pages = true;
var huge_page_threshold = 1e6;
var function calloc(t, count) {
   if( count == 0 ) { return 0, 0; }
   var byte_size = ffi.sizeof(t) * count;
   var mem, err;
   if( try_huge_pages && byte_size > huge_page_threshold ) {
      mem, err = S.mmap(null, byte_size, 'read, write',
                        'private, anonymous, hugetlb');
      if( ! mem ) {
         print("hugetlb mmap failed ("..tostring(err)..'), falling back.');
         // FIXME: Increase vm.nr_hugepages.  See
         // core.memory.reserve_new_page().
      }
   }
   if( ! mem ) {
      mem, err = S.mmap(null, byte_size, 'read, write',
                        'private, anonymous');
      if( ! mem ) { error("mmap failed: " .. tostring(err)); }
   }
   var ret = ffi.cast(ffi.typeof('$*', t), mem);
   ffi.gc(ret, function (ptr) { S.munmap(ptr, byte_size); });
   return ret, byte_size;
}

function CTable::reseed_hash_function(seed) {
   // The hash function's seed determines the hash value of an input,
   // and thus the iteration order for the table.  Usually this is a
   // feature: besides preventing hash-flood attacks, it also prevents a
   // quadratic-time complexity when initially populating a table from
   // entries stored in hash order, as can happen when reading in a
   // table from a serialization.  However, when SNABB_RANDOM_SEED is
   // set, then presumably we're trying to reproduce deterministic
   // behavior, as with quickcheck, and in that case a random seed can
   // make it more onerous to prove that make_table({A=B,C=D}) is equal
   // to make_table({A=B,C=D}) as the two tables could have different
   // iteration orders.  So, in "quickcheck mode", always seed hash
   // tables with the same value.
   if( seed ) {
      this.hash_seed = seed;
   } else if( lib.getenv("SNABB_RANDOM_SEED") ) {
      this.hash_seed = siphash.sip_hash_key_from_seed(
         lib.getenv("SNABB_RANDOM_SEED"));
   } else {
      this.hash_seed = siphash.random_sip_hash_key();
   }
   this.hash_fn = this.make_hash_fn();

   // FIXME: Invalidate associated lookup streamers, as they need new
   // multi_hash functions.
}

function CTable::resize(size) {
   assert(size >= (this.occupancy / this.max_occupancy_rate));
   assert(size == floor(size));
   var old_entries = this.entries;
   var old_size = this.size;
   var old_max_displacement = this.max_displacement;

   // Allocate double the requested number of entries to make sure there
   // is sufficient displacement if all hashes map to the last bucket.
   this.entries, this.byte_size = calloc(this.entry_type, size * 2);
   this.size = size;
   this.scale = this.size / HASH_MAX;
   this.occupancy = 0;
   this.max_displacement = 0;
   this.occupancy_hi = ceil(this.size * this.max_occupancy_rate);
   this.occupancy_lo = floor(this.size * this.min_occupancy_rate);
   for( i=0,this.size*2-1 ) { this.entries[i].hash = HASH_MAX; }

   if( old_size != 0 ) { this->reseed_hash_function(); }

   for( i=0,old_size+old_max_displacement-1 ) {
      if( old_entries[i].hash != HASH_MAX ) {
         this->add(old_entries[i].key, old_entries[i].value);
      }
   }
   if( this.resize_callback ) {
      this.resize_callback(this, old_size);
   }
}

function CTable::get_backing_size() {
   return this.byte_size;
}

var header_t = ffi.typeof([=[
struct {
   uint32_t size;
   uint32_t occupancy;
   uint32_t max_displacement;
   uint8_t hash_seed[16];
   double max_occupancy_rate;
   double min_occupancy_rate;
}
]=]);

function load(stream, params) {
   var header = stream->read_ptr(header_t);
   var params_copy = {};
   for( k,v in pairs(params) ) { params_copy[k] = v; }
   params_copy.initial_size = header.size;
   params_copy.min_occupancy_rate = header.min_occupancy_rate;
   params_copy.hash_seed = ffi.new('uint8_t[16]');
   ffi.copy(params_copy.hash_seed, header.hash_seed, 16);
   params_copy.max_occupancy_rate = header.max_occupancy_rate;
   var ctab = new(params_copy);
   ctab.occupancy = header.occupancy;
   ctab.max_displacement = header.max_displacement;
   var entry_count = ctab.size + ctab.max_displacement;

   // Slurp the entries directly into the ctable's backing store.
   // This ensures that the ctable is in hugepages.
   C.memcpy(ctab.entries,
            stream->read_array(ctab.entry_type, entry_count),
            ffi.sizeof(ctab.entry_type) * entry_count);

   return ctab;
}

function CTable::save(stream) {
   stream->write_ptr(header_t(this.size, this.occupancy, this.max_displacement,
                             this.hash_seed, this.max_occupancy_rate,
                             this.min_occupancy_rate),
                    header_t);
   stream->write_array(this.entries,
                      this.entry_type,
                      this.size + this.max_displacement);
}

function CTable::add(key, value, updates_allowed) {
   if( this.occupancy + 1 > this.occupancy_hi ) {
      // Note that resizing will invalidate all hash keys, so we need
      // to hash the key after resizing.
      this->resize(max(this.size * 2, 1)); // Could be current size is 0.
   }

   var hash = this.hash_fn(key);
   assert(hash >= 0);
   assert(hash < HASH_MAX);

   var entries = this.entries;
   var scale = this.scale;
   // local start_index = hash_to_index(hash, self.scale)
   var start_index = floor(hash*this.scale);
   var index = start_index;

   // Fast path.
   if( entries[index].hash == HASH_MAX && updates_allowed != 'required' ) {
      this.occupancy = this.occupancy + 1;
      var entry = entries + index;
      entry.hash = hash;
      entry.key = key;
      entry.value = value;
      return entry;
   }

   while( entries[index].hash < hash ) {
      ++index    ;
   }

   while( entries[index].hash == hash ) {
      var entry = entries + index;
      if( this.equal_fn(key, entry.key) ) {
         assert(updates_allowed, "key is already present in ctable");
         entry.key = key;
         entry.value = value;
         return entry;
      }
      ++index    ;
   }

   assert(updates_allowed != 'required', "key not found in ctable");

   this.max_displacement = max(this.max_displacement, index - start_index);

   if( entries[index].hash != HASH_MAX ) {
      // In a robin hood hash, we seek to spread the wealth around among
      // the members of the table.  An entry that can be stored exactly
      // where hash_to_index() maps it is a most wealthy entry.  The
      // farther from that initial position, the less wealthy.  Here we
      // have found an entry whose hash is greater than our hash,
      // meaning it has travelled less far, so we steal its position,
      // displacing it by one.  We might have to displace other entries
      // as well.
      var empty = index;
      while( entries[empty].hash != HASH_MAX ) { ++empty    ; }
      while( empty > index ) {
         entries[empty] = entries[empty - 1];
         var displacement = empty - hash_to_index(entries[empty].hash, scale);
         this.max_displacement = max(this.max_displacement, displacement);
         --empty    ;
      }
   }
           
   this.occupancy = this.occupancy + 1;
   var entry = entries + index;
   entry.hash = hash;
   entry.key = key;
   entry.value = value;
   return entry;
}

function CTable::update(key, value) {
   return this->add(key, value, 'required');
}

function CTable::lookup_ptr(key) {
   var hash = this.hash_fn(key);
   var entry = this.entries + hash_to_index(hash, this.scale);

   // Fast path in case we find it directly.
   if( hash == entry.hash && this.equal_fn(key, entry.key) ) {
      return entry;
   }

   while( entry.hash < hash ) { ++entry    ; }

   while( entry.hash == hash ) {
      if( this.equal_fn(key, entry.key) ) { return entry; }
      // Otherwise possibly a collision.
      ++entry    ;
   }

   // Not found.
   return null;
}

function CTable::lookup_and_copy(key, entry) {
   var entry_ptr = this->lookup_ptr(key);
   if( ! entry_ptr ) { return false; }
   ffi.copy(entry, entry_ptr, ffi.sizeof(entry));
   return true;
}

function CTable::remove_ptr(entry) {
   var scale = this.scale;
   var index = entry - this.entries;
   assert(index >= 0);
   assert(index < this.size + this.max_displacement);
   assert(entry.hash != HASH_MAX);

   this.occupancy = this.occupancy - 1;
   entry.hash = HASH_MAX;

   while( true ) {
      ++entry    ;
      ++index    ;
      if( entry.hash == HASH_MAX ) { break; }
      if( hash_to_index(entry.hash, scale) == index ) { break; }
      // Give to the poor.
      entry[-1] = entry[0];
      entry.hash = HASH_MAX;
   }

   if( this.occupancy < this.occupancy_lo ) {
      this->resize(max(ceil(this.size / 2), 1));
   }
}

// FIXME: Does NOT shrink max_displacement
function CTable::remove(key, missing_allowed) {
   var ptr = this->lookup_ptr(key);
   if( ! ptr ) {
      assert(missing_allowed, "key not found in ctable");
      return false;
   }
   this->remove_ptr(ptr);
   return true;
}

function CTable::make_lookup_streamer(width) {
   var res = {
      all_entries = this.entries,
      width = width,
      equal_fn = this.equal_fn,
      entries_per_lookup = this.max_displacement + 1,
      scale = this.scale,
      pointers = ffi.new('void*['..width..']'),
      entries = this.type(width),
      hashes = ffi.new('uint32_t[?]', width),
      // Binary search over N elements can return N if no entry was
      // found that was greater than or equal to the key.  We would
      // have to check the result of binary search to ensure that we
      // are reading a value in bounds.  To avoid this, allocate one
      // more entry.
      stream_entries = this.type(width * (this.max_displacement + 1) + 1)
   };
   // Give res.pointers sensible default values in case the first lookup
   // doesn't fill the pointers vector.
   for( i = 0, width-1 ) { res.pointers[i] = this.entries; }

   // Initialize the stream_entries to HASH_MAX for sanity.
   for( i = 0, width * (this.max_displacement + 1) ) {
      res.stream_entries[i].hash = HASH_MAX;
   }

   // Compile multi-copy and binary-search procedures that are
   // specialized for this table and this width.
   var entry_size = ffi.sizeof(this.entry_type);
   res.multi_copy = multi_copy.gen(width, res.entries_per_lookup * entry_size);
   res.multi_hash = this.make_multi_hash_fn(width);
   res.binary_search = binary_search.gen(res.entries_per_lookup, this.entry_type);

   return setmetatable(res, { __index = LookupStreamer });
}

function LookupStreamer::stream() {
   var width = this.width;
   var entries = this.entries;
   var pointers = this.pointers;
   var stream_entries = this.stream_entries;
   var entries_per_lookup = this.entries_per_lookup;
   var equal_fn = this.equal_fn;

   var key_offset = 4; // Skip past uint32_t hash.
   this.multi_hash(ffi.cast('uint8_t*', entries) + key_offset, this.hashes);

   for( i=0,width-1 ) {
      var hash = this.hashes[i];
      entries[i].hash = hash;
      pointers[i] = this.all_entries + hash_to_index(hash, this.scale);
   }

   this.multi_copy(stream_entries, pointers);

   // Copy results into entries.
   for( i=0,width-1 ) {
      var hash = entries[i].hash;
      var index = i * entries_per_lookup;
      var found = this.binary_search(stream_entries + index, hash);
      // It could be that we read one beyond the ENTRIES_PER_LOOKUP
      // entries allocated for this key; that's fine.  See note in
      // make_lookup_streamer.
      if( found.hash == hash ) {
         // Direct hit?
         if( equal_fn(found.key, entries[i].key) ) {
            entries[i].value = found.value;
         } else {
            // Mark this result as not found unless we prove
            // otherwise.
            entries[i].hash = HASH_MAX;

            // Collision?
            ++found    ;
            while( found.hash == hash ) {
               if( equal_fn(found.key, entries[i].key) ) {
                  // Yay!  Re-mark this result as found.
                  entries[i].hash = hash;
                  entries[i].value = found.value;
                  break;
               }
               ++found    ;
            }
         }
      } else {
         // Not found.
         entries[i].hash = HASH_MAX;
      }
   }
}

function LookupStreamer::is_empty(i) {
   assert(i >= 0 && i < this.width);
   return this.entries[i].hash == HASH_MAX;
}

function LookupStreamer::is_found(i) {
   return ! this->is_empty(i);
}

function CTable::selfcheck() {
   var occupancy = 0;
   var max_displacement = 0;

   var function fail(expected, op, found, what, where) {
      if( where ) { where = 'at '..where..': '; } else { where = ''; }
      error(where..what..' check: expected '..expected..op..'found '..found);
   }
   var function expect_eq(expected, found, what, where) {
      if( expected != found ) { fail(expected, '==', found, what, where); }
   }
   var function expect_le(expected, found, what, where) {
      if( expected > found ) { fail(expected, '<=', found, what, where); }
   }

   var prev = 0;
   for( i = 0,this.size+this.max_displacement-1 ) {
      var entry = this.entries[i];
      var hash = entry.hash;
      if( hash != 0xffffffff ) {
         expect_eq(this.hash_fn(entry.key), hash, 'hash', i);
         var index = hash_to_index(hash, this.scale);
         if( prev == 0xffffffff ) {
            expect_eq(index, i, 'undisplaced index', i);
         } else {
            expect_le(prev, hash, 'displaced hash', i);
         }
         ++occupancy    ;
         max_displacement = max(max_displacement, i - index);
      }
      prev = hash;
   }

   expect_eq(occupancy, this.occupancy, 'occupancy');
   // Compare using <= because remove_at doesn't update max_displacement.
   expect_le(max_displacement, this.max_displacement, 'max_displacement');
}

function CTable::dump() {
   var function dump_one(index) {
      io.write(index..':');
      var entry = this.entries[index];
      if( (entry.hash == HASH_MAX) ) {
         io.write('\n');
      } else {
         var distance = index - hash_to_index(entry.hash, this.scale);
         io.write(' hash: '..entry.hash..' (distance: '..distance..')\n');
         io.write('    key: '..tostring(entry.key)..'\n');
         io.write('  value: '..tostring(entry.value)..'\n');
      }
   }
   for( index=0,this.size-1+this.max_displacement ) { dump_one(index); }
}

function CTable::iterate() {
   var max_entry = this.entries + this.size + this.max_displacement;
   var function next_entry(max_entry, entry) {
      while( true ) {
         ++entry    ;
         if( entry >= max_entry ) { return null; }
         if( entry.hash != HASH_MAX ) { return entry; }
      }
   }
   return next_entry, max_entry, this.entries - 1;
}

function CTable::next_entry(offset, limit) {
   if( offset >= this.size + this.max_displacement ) {
      return 0, null;
   } else if( limit == null ) {
      limit = this.size + this.max_displacement;
   } else {
      limit = min(limit, this.size + this.max_displacement);
   }
   for( xoffset=offset, limit-1 ) {
      if( this.entries[xoffset].hash != HASH_MAX ) {
         return xoffset, this.entries + xoffset;
      }
   }
   return limit, null;
}

function selftest() {
   print("selftest: ctable");
   var bnot = require("bit").bnot;

   // 32-byte entries
   var occupancy = 2e6;
   var params = {
      key_type = ffi.typeof('uint32_t[1]'),
      value_type = ffi.typeof('int32_t[6]'),
      max_occupancy_rate = 0.4,
      initial_size = ceil(occupancy / 0.4)
   };
   var ctab = new(params);

   // Fill with {i} -> { bnot(i), ... }.
   var k = ffi.new('uint32_t[1]');
   var v = ffi.new('int32_t[6]');
   for( i = 1,occupancy ) {
      k[0] = i;
      for( j=0,5 ) { v[j] = bnot(i); }
      ctab->add(k, v);
   }

   for( i=1,2 ) {
      // The max displacement of this table will depend on the hash
      // seed, but we know for this input that it should rather small.
      // Assert here so that we can detect any future deviation or
      // regression.
      assert(ctab.max_displacement < 15, ctab.max_displacement);

      ctab->selfcheck();

      for( xi = 1, occupancy ) {
         k[0] = xi;
         var value = ctab->lookup_ptr(k).value[0];
         assert(value == bnot(xi));
      }
      ctab->selfcheck();

      // Incrementing by 31 instead of 1 just to save test time.
      {
         var entry = ctab.entry_type();
         for( xi = 1, occupancy, 31 ) {
            k[0] = xi;
            assert(ctab->lookup_and_copy(k, entry));
            assert(entry.key[0] == xi);
            assert(entry.value[0] == bnot(xi));
            ctab->remove(entry.key);
            assert(ctab->lookup_ptr(k) == null);
            ctab->add(entry.key, entry.value);
            assert(ctab->lookup_ptr(k).value[0] == bnot(xi));
         }
      }

      var iterated = 0;
      for( entry in ctab->iterate() ) { ++iterated    ; }
      assert(iterated == occupancy);

      // Save the table out to disk, reload it, and run the same
      // checks.
      var tmp = os.tmpname();
      {
         var file = io.open(tmp, 'wb');
         var function write(ptr, size) {
            file->write(ffi.string(ptr, size));
         }
         var stream = {};
         function stream::write_ptr(ptr, type) {
            assert(ffi.sizeof(ptr) == ffi.sizeof(type));
            write(ptr, ffi.sizeof(type));
         }
         function stream::write_array(ptr, type, count) {
            write(ptr, ffi.sizeof(type) * count);
         }
         ctab->save(stream);
         file->close();
      }
      {
         var file = io.open(tmp, 'rb');
         // keep references to avoid GCing too early
         var handle = {};
         var function read(size) {
            var buf = ffi.new('uint8_t[?]', size);
            ffi.copy(buf, file->read(size), size);
            table.insert(handle, buf);
            return buf;
         }
         var stream = {};
         function stream::read_ptr(type) {
            return ffi.cast(ffi.typeof('$*', type), read(ffi.sizeof(type)));
         }
         function stream::read_array(type, count) {
            return ffi.cast(ffi.typeof('$*', type),
                            read(ffi.sizeof(type) * count));
         }
         ctab = load(stream, params);
         file->close();
      }         
      os.remove(tmp);
   }

   // OK, all looking good with the normal interfaces; let's check out
   // streaming lookup.
   var width = 1;
   do {
      var streamer = ctab->make_lookup_streamer(width);
      for( i = 1, occupancy, width ) {
         var n = min(width, occupancy-i+1);
         for( j = 0, n-1 ) {
            streamer.entries[j].key[0] = i + j;
         }

         streamer->stream();
         for( j = 0, n-1 ) {
            assert(streamer->is_found(j));
            var value = streamer.entries[j].value[0];
            assert(value == bnot(i + j));
         }
      }
      width *=   2;
   } while(!( width > 256) );

   // A check that our equality functions work as intended.
   var numbers_equal = make_equal_fn(ffi.typeof('int'));
   assert(numbers_equal(1,1));
   assert(! numbers_equal(1,2));

   var function check_bytes_equal(type, a, b) {
      var equal_fn = make_equal_fn(type);
      var hash_fn = compute_hash_fn(type);
      assert(equal_fn(ffi.new(type, a), ffi.new(type, a)));
      assert(! equal_fn(ffi.new(type, a), ffi.new(type, b)));
      assert(hash_fn(ffi.new(type, a)) == hash_fn(ffi.new(type, a)));
      assert(hash_fn(ffi.new(type, a)) != hash_fn(ffi.new(type, b)));
   }
   check_bytes_equal(ffi.typeof('uint16_t[1]'), {1}, {2});         // 2 byte
   check_bytes_equal(ffi.typeof('uint32_t[1]'), {1}, {2});         // 4 byte
   check_bytes_equal(ffi.typeof('uint16_t[3]'), {1,1,1}, {1,1,2}); // 6 byte
   check_bytes_equal(ffi.typeof('uint32_t[2]'), {1,1}, {1,2});     // 8 byte
   check_bytes_equal(ffi.typeof('uint32_t[3]'), {1,1,1}, {1,1,2}); // 12 byte

   print("selftest: ok");
}
